# CodeAlpha_Emotion-Recognition-from-Speech

# ğŸ¤ Speech Emotion Recognition Web App

An interactive **Speech Emotion Recognition** system built with **Python, Deep Learning, and Flask** that can detect human emotions from speech audio (`.wav` / `.mp3`) using an LSTM model trained on the **TESS dataset**.  
The app provides a **modern web interface** with drag-and-drop upload for instant predictions.

---

## ğŸ“Œ Features
- ğŸ¯ **Emotion Detection** from speech using deep learning (MFCC features + LSTM model)
- ğŸ¨ **Modern responsive UI** with drag & drop or file selection
- ğŸ“Š **Confidence meter** showing model prediction probability
- âš¡ **No file storage** â€” audio is processed in-memory
- ğŸ”— **Flask backend** with API endpoint for predictions
- ğŸŒˆ **Emotion icons & styling** for better visual feedback

---

## ğŸ›  Tech Stack
**Backend:**
- Python 3.x
- Flask
- Librosa (audio feature extraction)
- TensorFlow / Keras (LSTM deep learning model)
- NumPy, scikit-learn

**Frontend:**
- HTML5, CSS3
- Vanilla JavaScript (fetch API for AJAX calls)
- Responsive design

---

## ğŸ“‚ Dataset
This project uses the **[TESS Toronto Emotional Speech Set](https://tspace.library.utoronto.ca/handle/1807/24487)** dataset for training.
> *Note: Dataset is not included in the repo. Please download it separately.*

---

## ğŸ“¦ Installation & Setup

### 1ï¸âƒ£ Clone the repository
- git clone https://github.com/yourusername/speech-emotion-recognition.git
- cd speech-emotion-recognition


### 2ï¸âƒ£ Create & activate a virtual environment
- python -m venv venv
- Activate:
- Windows
- venv\Scripts\activate

- macOS/Linux
- source venv/bin/activate

### 3ï¸âƒ£ Install dependencies
- pip install -r requirements.txt

### 4ï¸âƒ£ Prepare the dataset
- Download and extract the TESS dataset.
- Place the dataset folder in your project directory.
- Update `DATA_DIR` in `prepare_data.py` to point to your dataset path.

### 5ï¸âƒ£ Preprocess data & train the model
- python prepare_data.py
- python train_model.py

### This will generate:
- `emotion_recognition_lstm.h5` â†’ trained LSTM model
- `label_classes.npy` â†’ encoded emotion labels
- Prepared `.npy` feature files

---

## ğŸš€ Run the Web App
-  python app.py
-  Open your browser and go to:
-  Open your browser and go to:
- Drag & drop or browse for an audio file.
- Instantly get predicted emotion with confidence score.

---

## ğŸ“ Project Structure
speech-emotion-recognition/

â”‚

â”œâ”€â”€ app.py # Flask backend (runs the web app)

â”œâ”€â”€ prepare_data.py # Preprocess dataset, extract MFCCs, encode labels

â”œâ”€â”€ train_model.py # Train the LSTM model

â”œâ”€â”€ requirements.txt # Python dependencies

â”‚

â”œâ”€â”€ emotion_recognition_lstm.h5 # Saved trained model

â”œâ”€â”€ label_classes.npy # Saved encoded classes

â”œâ”€â”€ predict_emotion # A Simple file to predict with web interface

â”‚

â”œâ”€â”€ templates/

â”‚ â””â”€â”€ index.html # Frontend HTML

â”‚

â”œâ”€â”€ static/

â”‚ â””â”€â”€ style.css # Frontend CSS styling

â”‚

â””â”€â”€ README.md # Project documentation





---

## ğŸ”® Future Improvements
- Real-time microphone recording & prediction
- More advanced deep learning models (CNN-LSTM hybrids)
- Multi-language emotion recognition
- Deployment to cloud (Heroku, Render, etc.)

---


